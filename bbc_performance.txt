************************************************
a) MultinomialNB default values, try 1

b)
Confusion matrix
NOTE: I had difficulty making this work because the function in the assignment handout is deprecated as in python 3.9,
which is the version on my computer. Instead, the confusion matrix is on the file called confusion-matrix-try1.pdf
c) Precision, recall, F1 measure
               precision    recall  f1-score   support

     business       0.95      0.96      0.95       110
entertainment       0.97      0.82      0.89        74
     politics       0.89      0.97      0.93        77
        sport       0.97      0.99      0.98       110
         tech       0.93      0.93      0.93        74

     accuracy                           0.94       445
    macro avg       0.94      0.94      0.94       445
 weighted avg       0.95      0.94      0.94       445

d)
Accuracy: 0.9438202247191011
Macro-average F1: 0.9383114673816039
Weighted-average F1: 0.9431460757681432
e)
business: 0.2292134831460674
entertainment: 0.17348314606741572
politics: 0.18741573033707865
sport: 0.22966292134831462
tech: 0.1802247191011236
f) 29422
g)
Businness: 166868
Entertainment: 128640
Politics: 190208
Sport: 170802
Tech: 202924
h)
859442
i)
Business: 18932, 0.6434640745020733%
Entertainment: 18777, 0.6381959078240772%
Politics: 19268, 0.6548841003330841%
Sport: 19979, 0.6790496907076338%
Tech: 18213, 0.6190265787505947%
j)
10006
k)
Sport: -10.217335220458773
Super: -9.95094354451887

**************************************************************************
a) MultinomialNB default values, try 2

b)
Confusion matrix
NOTE: I had difficulty making this work because the function in the assignment handout is deprecated as in python 3.9,
which is the version on my computer. Instead, the confusion matrix is on the file called confusion-matrix-try2.pdf
c) Precision, recall, F1 measure
               precision    recall  f1-score   support

     business       0.98      0.98      0.98       100
entertainment       1.00      0.83      0.91        75
     politics       0.85      0.99      0.91        75
        sport       0.95      1.00      0.97       109
         tech       0.98      0.92      0.95        86

     accuracy                           0.95       445
    macro avg       0.95      0.94      0.94       445
 weighted avg       0.95      0.95      0.95       445

d)
Accuracy: 0.9483146067415731
Macro-average F1: 0.9436023612220197
Weighted-average F1: 0.9479715883174956
e)
business: 0.2292134831460674
entertainment: 0.17348314606741572
politics: 0.18741573033707865
sport: 0.22966292134831462
tech: 0.1802247191011236
f) 29422
g)
Businness: 166868
Entertainment: 128640
Politics: 190208
Sport: 170802
Tech: 202924
h)
859442
i)
Business: 18690, 0.6352389368499762%
Entertainment: 19037, 0.6470328325742641%
Politics: 19116, 0.6497178981714363%
Sport: 19995, 0.6795935014614914%
Tech: 18537, 0.6300387465162124%
j)
10006
k)
Sport: -10.248455311611114
Super: -10.056959912704183

***********************************************************************
a) MultinomialNB smoothing value of 0.0001

b)
Confusion matrix
NOTE: I had difficulty making this work because the function in the assignment handout is deprecated as in python 3.9,
which is the version on my computer. Instead, the confusion matrix is on the file called confusion-matrix00001.pdf
c) Precision, recall, F1 measure
               precision    recall  f1-score   support

     business       0.99      0.97      0.98        97
entertainment       1.00      0.93      0.96        85
     politics       0.98      1.00      0.99        90
        sport       1.00      1.00      1.00        93
         tech       0.92      0.99      0.95        80

     accuracy                           0.98       445
    macro avg       0.98      0.98      0.98       445
 weighted avg       0.98      0.98      0.98       445

d)
Accuracy: 0.9775280898876404
Macro-average F1: 0.976679903747932
Weighted-average F1: 0.9775842199850511
e)
business: 0.2292134831460674
entertainment: 0.17348314606741572
politics: 0.18741573033707865
sport: 0.22966292134831462
tech: 0.1802247191011236
f) 29422
g)
Businness: 166868
Entertainment: 128640
Politics: 190208
Sport: 170802
Tech: 202924
h)
859442
i)
Business: 18626, 0.6330636938345455%
Entertainment: 19192, 0.6523009992522603%
Politics: 19398, 0.6593025627081776%
Sport: 19696, 0.6694310379987765%
Tech: 18169, 0.6175310991774863%
j)
10006
k)
Sport: -9.68614976691059
Super: -8.836136490955557


***********************************************************************
a) MultinomialNB smoothing value of 0.9

b)
Confusion matrix
NOTE: I had difficulty making this work because the function in the assignment handout is deprecated as in python 3.9,
which is the version on my computer. Instead, the confusion matrix is on the file called confusion-matrix09.pdf
c) Precision, recall, F1 measure
               precision    recall  f1-score   support

     business       0.95      0.99      0.97        95
entertainment       0.98      0.85      0.91        74
     politics       0.98      0.95      0.96       100
        sport       0.99      1.00      1.00       114
         tech       0.87      0.98      0.92        62

     accuracy                           0.96       445
    macro avg       0.96      0.95      0.95       445
 weighted avg       0.96      0.96      0.96       445

d)
Accuracy: 0.9595505617977528
Macro-average F1: 0.9532916520601631
Weighted-average F1: 0.9592786230970011
e)
business: 0.2292134831460674
entertainment: 0.17348314606741572
politics: 0.18741573033707865
sport: 0.22966292134831462
tech: 0.1802247191011236
f) 29422
g)
Businness: 166868
Entertainment: 128640
Politics: 190208
Sport: 170802
Tech: 202924
h)
859442
i)
Business: 18767, 0.6378560261029161%
Entertainment: 18836, 0.6402012099789274%
Politics: 19220, 0.6532526680715112%
Sport: 19968, 0.6786758208143566%
Tech: 17972, 0.6108354292706138%
j)
10006
k)
Sport: -10.21052963101681
Super: -10.009059610617788


